train.py:40: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(model.parameters(), clip)
Train Epoch: 1 [0/229 (0%)]	 KLD Loss: 3912.089355 	 NLL Loss: 31257.330078
====> Epoch: 1 Average loss: 2845.3996
Train Epoch: 2 [0/229 (0%)]	 KLD Loss: 49.345928 	 NLL Loss: 4571.550781
====> Epoch: 2 Average loss: 887.8027
Train Epoch: 3 [0/229 (0%)]	 KLD Loss: 93.105934 	 NLL Loss: 4151.144531
====> Epoch: 3 Average loss: 762.0704
Train Epoch: 4 [0/229 (0%)]	 KLD Loss: 25.882885 	 NLL Loss: 3786.774414
====> Epoch: 4 Average loss: 701.7610
Train Epoch: 5 [0/229 (0%)]	 KLD Loss: 26.256834 	 NLL Loss: 3709.013916
====> Epoch: 5 Average loss: 689.1669
====> Valid set loss: KLD Loss = 3.4860, NLL Loss = 669.0179 
Train Epoch: 6 [0/229 (0%)]	 KLD Loss: 25.941927 	 NLL Loss: 3697.136475
====> Epoch: 6 Average loss: 685.1003
Train Epoch: 7 [0/229 (0%)]	 KLD Loss: 23.948641 	 NLL Loss: 3680.866455
====> Epoch: 7 Average loss: 681.3419
Train Epoch: 8 [0/229 (0%)]	 KLD Loss: 19.522091 	 NLL Loss: 3684.668457
====> Epoch: 8 Average loss: 678.6457
Train Epoch: 9 [0/229 (0%)]	 KLD Loss: 18.565733 	 NLL Loss: 3674.020264
====> Epoch: 9 Average loss: 676.4041
Train Epoch: 10 [0/229 (0%)]	 KLD Loss: 21.281544 	 NLL Loss: 3664.286377
====> Epoch: 10 Average loss: 674.3858
====> Valid set loss: KLD Loss = 3.1995, NLL Loss = 658.4720 
Train Epoch: 11 [0/229 (0%)]	 KLD Loss: 24.200777 	 NLL Loss: 3642.581787
====> Epoch: 11 Average loss: 671.4952
Train Epoch: 12 [0/229 (0%)]	 KLD Loss: 28.999987 	 NLL Loss: 3602.064697
====> Epoch: 12 Average loss: 664.4422
Train Epoch: 13 [0/229 (0%)]	 KLD Loss: 25.787947 	 NLL Loss: 3534.490967
====> Epoch: 13 Average loss: 658.0432
Train Epoch: 14 [0/229 (0%)]	 KLD Loss: 30.898663 	 NLL Loss: 3468.542236
====> Epoch: 14 Average loss: 653.3758
Train Epoch: 15 [0/229 (0%)]	 KLD Loss: 44.246597 	 NLL Loss: 3431.709229
====> Epoch: 15 Average loss: 649.9371
====> Valid set loss: KLD Loss = 13.3865, NLL Loss = 625.7288 
Train Epoch: 16 [0/229 (0%)]	 KLD Loss: 63.518803 	 NLL Loss: 3412.988525
====> Epoch: 16 Average loss: 646.2264
Train Epoch: 17 [0/229 (0%)]	 KLD Loss: 71.829796 	 NLL Loss: 3376.554932
====> Epoch: 17 Average loss: 643.2581
Train Epoch: 18 [0/229 (0%)]	 KLD Loss: 77.805527 	 NLL Loss: 3376.874268
====> Epoch: 18 Average loss: 640.7963
Train Epoch: 19 [0/229 (0%)]	 KLD Loss: 82.883942 	 NLL Loss: 3333.895264
====> Epoch: 19 Average loss: 636.1258
Train Epoch: 20 [0/229 (0%)]	 KLD Loss: 87.560905 	 NLL Loss: 3335.592529
====> Epoch: 20 Average loss: 631.1591
====> Valid set loss: KLD Loss = 22.4346, NLL Loss = 603.7454 
Train Epoch: 21 [0/229 (0%)]	 KLD Loss: 110.393265 	 NLL Loss: 3296.585205
====> Epoch: 21 Average loss: 627.2833
Train Epoch: 22 [0/229 (0%)]	 KLD Loss: 114.593674 	 NLL Loss: 3260.681396
====> Epoch: 22 Average loss: 619.2783
Train Epoch: 23 [0/229 (0%)]	 KLD Loss: 145.709229 	 NLL Loss: 3222.011719
====> Epoch: 23 Average loss: 612.4595
Train Epoch: 24 [0/229 (0%)]	 KLD Loss: 140.208466 	 NLL Loss: 3187.548096
====> Epoch: 24 Average loss: 605.8239
Train Epoch: 25 [0/229 (0%)]	 KLD Loss: 163.930435 	 NLL Loss: 3162.862793
====> Epoch: 25 Average loss: 600.6051
====> Valid set loss: KLD Loss = 34.2701, NLL Loss = 559.8151 
Train Epoch: 26 [0/229 (0%)]	 KLD Loss: 168.662979 	 NLL Loss: 3116.207764
====> Epoch: 26 Average loss: 595.6761
Train Epoch: 27 [0/229 (0%)]	 KLD Loss: 177.718048 	 NLL Loss: 3111.626953
====> Epoch: 27 Average loss: 589.3077
Train Epoch: 28 [0/229 (0%)]	 KLD Loss: 196.987198 	 NLL Loss: 3052.940186
====> Epoch: 28 Average loss: 584.3583
Train Epoch: 29 [0/229 (0%)]	 KLD Loss: 216.967178 	 NLL Loss: 3017.863525
====> Epoch: 29 Average loss: 578.4890
Train Epoch: 30 [0/229 (0%)]	 KLD Loss: 244.832733 	 NLL Loss: 2921.663086
====> Epoch: 30 Average loss: 569.1773
====> Valid set loss: KLD Loss = 53.4887, NLL Loss = 509.4906 
Train Epoch: 31 [0/229 (0%)]	 KLD Loss: 259.946991 	 NLL Loss: 2902.313232
====> Epoch: 31 Average loss: 562.6350
Train Epoch: 32 [0/229 (0%)]	 KLD Loss: 284.753723 	 NLL Loss: 2818.312256
====> Epoch: 32 Average loss: 555.2921
Train Epoch: 33 [0/229 (0%)]	 KLD Loss: 282.512970 	 NLL Loss: 2783.165527
====> Epoch: 33 Average loss: 542.0759
Train Epoch: 34 [0/229 (0%)]	 KLD Loss: 271.855438 	 NLL Loss: 2837.290283
====> Epoch: 34 Average loss: 529.1309
Train Epoch: 35 [0/229 (0%)]	 KLD Loss: 285.523834 	 NLL Loss: 2775.700928
====> Epoch: 35 Average loss: 517.5853
====> Valid set loss: KLD Loss = 58.0755, NLL Loss = 464.2530 
Train Epoch: 36 [0/229 (0%)]	 KLD Loss: 283.449768 	 NLL Loss: 2791.184814
====> Epoch: 36 Average loss: 511.6485
Train Epoch: 37 [0/229 (0%)]	 KLD Loss: 300.627502 	 NLL Loss: 2728.234619
====> Epoch: 37 Average loss: 505.6554
Train Epoch: 38 [0/229 (0%)]	 KLD Loss: 306.650299 	 NLL Loss: 2695.666748
====> Epoch: 38 Average loss: 501.1868
Train Epoch: 39 [0/229 (0%)]	 KLD Loss: 312.527954 	 NLL Loss: 2674.672607
====> Epoch: 39 Average loss: 497.9925
Train Epoch: 40 [0/229 (0%)]	 KLD Loss: 326.412201 	 NLL Loss: 2659.009766
====> Epoch: 40 Average loss: 496.4519
====> Valid set loss: KLD Loss = 68.3143, NLL Loss = 440.7036 
Train Epoch: 41 [0/229 (0%)]	 KLD Loss: 331.190613 	 NLL Loss: 2650.298828
====> Epoch: 41 Average loss: 492.8836
Train Epoch: 42 [0/229 (0%)]	 KLD Loss: 318.959045 	 NLL Loss: 2653.953125
====> Epoch: 42 Average loss: 489.2963
Train Epoch: 43 [0/229 (0%)]	 KLD Loss: 336.174805 	 NLL Loss: 2574.771729
====> Epoch: 43 Average loss: 484.7955
Train Epoch: 44 [0/229 (0%)]	 KLD Loss: 344.067230 	 NLL Loss: 2591.504150
====> Epoch: 44 Average loss: 481.6996
Train Epoch: 45 [0/229 (0%)]	 KLD Loss: 349.879150 	 NLL Loss: 2558.463867
====> Epoch: 45 Average loss: 477.7776
====> Valid set loss: KLD Loss = 76.1417, NLL Loss = 414.3266 
Train Epoch: 46 [0/229 (0%)]	 KLD Loss: 370.659546 	 NLL Loss: 2522.242920
====> Epoch: 46 Average loss: 475.7128
Train Epoch: 47 [0/229 (0%)]	 KLD Loss: 348.731537 	 NLL Loss: 2496.480225
====> Epoch: 47 Average loss: 473.0863
Train Epoch: 48 [0/229 (0%)]	 KLD Loss: 341.288544 	 NLL Loss: 2506.123779
====> Epoch: 48 Average loss: 469.9178
Train Epoch: 49 [0/229 (0%)]	 KLD Loss: 339.285492 	 NLL Loss: 2472.282471
====> Epoch: 49 Average loss: 467.0907
Train Epoch: 50 [0/229 (0%)]	 KLD Loss: 354.086273 	 NLL Loss: 2445.046631
====> Epoch: 50 Average loss: 464.5126
====> Valid set loss: KLD Loss = 76.2822, NLL Loss = 402.9881 
Train Epoch: 51 [0/229 (0%)]	 KLD Loss: 360.962463 	 NLL Loss: 2401.011963
Traceback (most recent call last):
  File "train.py", line 148, in <module>
    train(epoch)
  File "train.py", line 34, in train
    kld_loss, nll_loss, _, _ = model(data)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/syseo/workspace/FIVO_Gumbel/model.py", line 126, in forward
    #computing losses
  File "/home/syseo/workspace/FIVO_Gumbel/model.py", line 201, in _kld_gauss_dist
    cov2 = torch.diag(std_2 ** 2)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py", line 149, in __init__
    self._unbroadcasted_scale_tril = torch.cholesky(covariance_matrix)
RuntimeError: cholesky_cpu: For batch 0: U(1,1) is zero, singular U.

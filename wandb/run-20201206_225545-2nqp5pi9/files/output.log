train.py:40: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(model.parameters(), clip)
Train Epoch: 1 [0/229 (0%)]	 KLD Loss: 3912.089111 	 NLL Loss: 31257.330078
====> Epoch: 1 Average loss: 2845.3996
Train Epoch: 2 [0/229 (0%)]	 KLD Loss: 49.345974 	 NLL Loss: 4571.550293
====> Epoch: 2 Average loss: 887.8027
Train Epoch: 3 [0/229 (0%)]	 KLD Loss: 93.105927 	 NLL Loss: 4151.144531
====> Epoch: 3 Average loss: 762.0704
Train Epoch: 4 [0/229 (0%)]	 KLD Loss: 25.882914 	 NLL Loss: 3786.774414
====> Epoch: 4 Average loss: 701.7610
Train Epoch: 5 [0/229 (0%)]	 KLD Loss: 26.257441 	 NLL Loss: 3709.015137
====> Epoch: 5 Average loss: 689.1664
Train Epoch: 6 [0/229 (0%)]	 KLD Loss: 26.102377 	 NLL Loss: 3693.024902
====> Epoch: 6 Average loss: 684.8009
Train Epoch: 7 [0/229 (0%)]	 KLD Loss: 21.044827 	 NLL Loss: 3675.018066
====> Epoch: 7 Average loss: 681.4857
Train Epoch: 8 [0/229 (0%)]	 KLD Loss: 23.132912 	 NLL Loss: 3663.439941
====> Epoch: 8 Average loss: 678.5593
Train Epoch: 9 [0/229 (0%)]	 KLD Loss: 21.132742 	 NLL Loss: 3649.624512
====> Epoch: 9 Average loss: 676.2040
Train Epoch: 10 [0/229 (0%)]	 KLD Loss: 21.475363 	 NLL Loss: 3650.532471
====> Epoch: 10 Average loss: 676.3691
====> Valid set loss: KLD Loss = 3.5947, NLL Loss = 657.1191 
Train Epoch: 11 [0/229 (0%)]	 KLD Loss: 26.319132 	 NLL Loss: 3615.415039
====> Epoch: 11 Average loss: 669.5179
Train Epoch: 12 [0/229 (0%)]	 KLD Loss: 25.212782 	 NLL Loss: 3606.939941
====> Epoch: 12 Average loss: 663.1529
Train Epoch: 13 [0/229 (0%)]	 KLD Loss: 36.366291 	 NLL Loss: 3522.697998
====> Epoch: 13 Average loss: 656.6982
Train Epoch: 14 [0/229 (0%)]	 KLD Loss: 55.924923 	 NLL Loss: 3440.066895
====> Epoch: 14 Average loss: 652.3368
Train Epoch: 15 [0/229 (0%)]	 KLD Loss: 64.977707 	 NLL Loss: 3409.684082
====> Epoch: 15 Average loss: 649.1745
Train Epoch: 16 [0/229 (0%)]	 KLD Loss: 78.696419 	 NLL Loss: 3363.473877
====> Epoch: 16 Average loss: 645.1850
Train Epoch: 17 [0/229 (0%)]	 KLD Loss: 70.081085 	 NLL Loss: 3371.563232
====> Epoch: 17 Average loss: 641.8841
Train Epoch: 18 [0/229 (0%)]	 KLD Loss: 78.344330 	 NLL Loss: 3348.075928
====> Epoch: 18 Average loss: 636.4327
Train Epoch: 19 [0/229 (0%)]	 KLD Loss: 80.619507 	 NLL Loss: 3313.902588
====> Epoch: 19 Average loss: 631.9219
Train Epoch: 20 [0/229 (0%)]	 KLD Loss: 100.137337 	 NLL Loss: 3331.287842
====> Epoch: 20 Average loss: 628.7330
====> Valid set loss: KLD Loss = 21.4403, NLL Loss = 599.7960 
Train Epoch: 21 [0/229 (0%)]	 KLD Loss: 102.664772 	 NLL Loss: 3265.263428
====> Epoch: 21 Average loss: 622.0072
Train Epoch: 22 [0/229 (0%)]	 KLD Loss: 115.778099 	 NLL Loss: 3228.241943
====> Epoch: 22 Average loss: 614.2053
Train Epoch: 23 [0/229 (0%)]	 KLD Loss: 145.330612 	 NLL Loss: 3141.645020
====> Epoch: 23 Average loss: 605.5475
Train Epoch: 24 [0/229 (0%)]	 KLD Loss: 154.759369 	 NLL Loss: 3163.801758
====> Epoch: 24 Average loss: 602.6030
Train Epoch: 25 [0/229 (0%)]	 KLD Loss: 157.805862 	 NLL Loss: 3134.074707
====> Epoch: 25 Average loss: 598.4947
Train Epoch: 26 [0/229 (0%)]	 KLD Loss: 163.689438 	 NLL Loss: 3095.136963
====> Epoch: 26 Average loss: 593.4399
Train Epoch: 27 [0/229 (0%)]	 KLD Loss: 173.246811 	 NLL Loss: 3069.927734
====> Epoch: 27 Average loss: 588.9645
Train Epoch: 28 [0/229 (0%)]	 KLD Loss: 176.977982 	 NLL Loss: 3062.258789
====> Epoch: 28 Average loss: 585.4054
Train Epoch: 29 [0/229 (0%)]	 KLD Loss: 177.488403 	 NLL Loss: 3046.210938
====> Epoch: 29 Average loss: 579.7315
Train Epoch: 30 [0/229 (0%)]	 KLD Loss: 206.206406 	 NLL Loss: 2995.646729
====> Epoch: 30 Average loss: 572.1861
====> Valid set loss: KLD Loss = 47.0961, NLL Loss = 518.0647 
Train Epoch: 31 [0/229 (0%)]	 KLD Loss: 227.144745 	 NLL Loss: 2917.791016
====> Epoch: 31 Average loss: 564.2688
Train Epoch: 32 [0/229 (0%)]	 KLD Loss: 229.265274 	 NLL Loss: 2874.234863
====> Epoch: 32 Average loss: 556.6931
Train Epoch: 33 [0/229 (0%)]	 KLD Loss: 239.553329 	 NLL Loss: 2834.811523
====> Epoch: 33 Average loss: 545.8353
Train Epoch: 34 [0/229 (0%)]	 KLD Loss: 271.070740 	 NLL Loss: 2783.185791
====> Epoch: 34 Average loss: 532.9755
Train Epoch: 35 [0/229 (0%)]	 KLD Loss: 282.228027 	 NLL Loss: 2779.023193
====> Epoch: 35 Average loss: 523.1618
Train Epoch: 36 [0/229 (0%)]	 KLD Loss: 316.362396 	 NLL Loss: 2725.383545
====> Epoch: 36 Average loss: 513.5922
Train Epoch: 37 [0/229 (0%)]	 KLD Loss: 293.098999 	 NLL Loss: 2675.293213
====> Epoch: 37 Average loss: 506.9639
Train Epoch: 38 [0/229 (0%)]	 KLD Loss: 304.076050 	 NLL Loss: 2670.251709
====> Epoch: 38 Average loss: 503.1761
Train Epoch: 39 [0/229 (0%)]	 KLD Loss: 300.592010 	 NLL Loss: 2705.804932
====> Epoch: 39 Average loss: 500.4079
Train Epoch: 40 [0/229 (0%)]	 KLD Loss: 315.463013 	 NLL Loss: 2707.997070
====> Epoch: 40 Average loss: 498.0418
====> Valid set loss: KLD Loss = 64.1888, NLL Loss = 445.8574 
Train Epoch: 41 [0/229 (0%)]	 KLD Loss: 314.343201 	 NLL Loss: 2656.837646
====> Epoch: 41 Average loss: 494.9624
Train Epoch: 42 [0/229 (0%)]	 KLD Loss: 334.589355 	 NLL Loss: 2566.686523
====> Epoch: 42 Average loss: 488.5463
Train Epoch: 43 [0/229 (0%)]	 KLD Loss: 343.689636 	 NLL Loss: 2558.378418
====> Epoch: 43 Average loss: 486.4648
Train Epoch: 44 [0/229 (0%)]	 KLD Loss: 348.134583 	 NLL Loss: 2590.146240
====> Epoch: 44 Average loss: 482.8382
Train Epoch: 45 [0/229 (0%)]	 KLD Loss: 346.783630 	 NLL Loss: 2537.732910
====> Epoch: 45 Average loss: 480.6337
Train Epoch: 46 [0/229 (0%)]	 KLD Loss: 346.191681 	 NLL Loss: 2502.826172
====> Epoch: 46 Average loss: 478.5761
Train Epoch: 47 [0/229 (0%)]	 KLD Loss: 352.795319 	 NLL Loss: 2490.138428
====> Epoch: 47 Average loss: 475.3742
Train Epoch: 48 [0/229 (0%)]	 KLD Loss: 345.535553 	 NLL Loss: 2521.296143
====> Epoch: 48 Average loss: 472.6989
Train Epoch: 49 [0/229 (0%)]	 KLD Loss: 356.565216 	 NLL Loss: 2467.544434
====> Epoch: 49 Average loss: 469.7745
Train Epoch: 50 [0/229 (0%)]	 KLD Loss: 337.904755 	 NLL Loss: 2507.556885
====> Epoch: 50 Average loss: 468.2819
====> Valid set loss: KLD Loss = 70.5605, NLL Loss = 411.9877 
Train Epoch: 51 [0/229 (0%)]	 KLD Loss: 331.606140 	 NLL Loss: 2479.869385
====> Epoch: 51 Average loss: 464.5594
Train Epoch: 52 [0/229 (0%)]	 KLD Loss: 341.997925 	 NLL Loss: 2427.578125
====> Epoch: 52 Average loss: 461.7873
Train Epoch: 53 [0/229 (0%)]	 KLD Loss: 356.143097 	 NLL Loss: 2380.988525
====> Epoch: 53 Average loss: 459.6908
Train Epoch: 54 [0/229 (0%)]	 KLD Loss: 396.117188 	 NLL Loss: 2347.849854
====> Epoch: 54 Average loss: 458.2966
Train Epoch: 55 [0/229 (0%)]	 KLD Loss: 387.375397 	 NLL Loss: 2349.298340
====> Epoch: 55 Average loss: nan
Train Epoch: 56 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
====> Epoch: 56 Average loss: nan
Train Epoch: 57 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
====> Epoch: 57 Average loss: nan
Train Epoch: 58 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
====> Epoch: 58 Average loss: nan
Train Epoch: 59 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
====> Epoch: 59 Average loss: nan
Train Epoch: 60 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
====> Epoch: 60 Average loss: nan
====> Valid set loss: KLD Loss = nan, NLL Loss = nan 
Train Epoch: 61 [0/229 (0%)]	 KLD Loss: nan 	 NLL Loss: nan
Traceback (most recent call last):
  File "train.py", line 148, in <module>
    train(epoch)
  File "train.py", line 36, in train
    loss.backward()
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/distributions/distribution.py:134: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead
  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)
Train Epoch: 1 [0/229 (0%)]	 Sequence LL: -4809.464844 KL: 115.132027 timestep LL : -62.553024,  timestep IWAE : -62.555832
Train Epoch: 1 [40/229 (17%)]	 Sequence LL: -3857.110107 KL: 81.376373 timestep LL : -62.225220,  timestep IWAE : -62.226170
Train Epoch: 1 [80/229 (34%)]	 Sequence LL: -3757.836914 KL: 69.804008 timestep LL : -61.857365,  timestep IWAE : -61.857216
Train Epoch: 1 [120/229 (52%)]	 Sequence LL: -4102.501465 KL: 66.648972 timestep LL : -61.455498,  timestep IWAE : -61.456657
Train Epoch: 1 [160/229 (69%)]	 Sequence LL: -4403.516602 KL: 61.692654 timestep LL : -60.943527,  timestep IWAE : -60.943626
Train Epoch: 1 [200/229 (86%)]	 Sequence LL: -3310.622314 KL: 38.566223 timestep LL : -60.469170,  timestep IWAE : -60.475513
====> Epoch: 1 Average LL per sequence: -3704.4588, Average LL per timestep: -61.4524, IWAE per timestep : -61.452682
====> Valid set loss: Avg. Marginal LL = -3631.4380, KL = 9.0859, Marginal LL per timestep = -59.9852, IWAE bound per timestep = -59.9874
== Best valid loss! Start Testing.. 
====> Test set loss:  Avg. Marginal LL = -3681.0435, Avg. Marginal LL per timestep = -59.9923, IWAE bound per timestep = -59.9963
Train Epoch: 2 [0/229 (0%)]	 Sequence LL: -4602.324219 KL: 46.104160 timestep LL : -59.854019,  timestep IWAE : -59.859550
Train Epoch: 2 [40/229 (17%)]	 Sequence LL: -3674.142090 KL: 29.577229 timestep LL : -59.273514,  timestep IWAE : -59.271744
Train Epoch: 2 [80/229 (34%)]	 Sequence LL: -3541.934814 KL: 21.131027 timestep LL : -58.303902,  timestep IWAE : -58.322670
Train Epoch: 2 [120/229 (52%)]	 Sequence LL: -3784.078369 KL: 17.506100 timestep LL : -56.693516,  timestep IWAE : -56.724163
Train Epoch: 2 [160/229 (69%)]	 Sequence LL: -3892.619385 KL: 17.390827 timestep LL : -53.869011,  timestep IWAE : -53.884338
Train Epoch: 2 [200/229 (86%)]	 Sequence LL: -2704.477051 KL: 19.386116 timestep LL : -49.410679,  timestep IWAE : -49.425316
====> Epoch: 2 Average LL per sequence: -3348.6605, Average LL per timestep: -55.5895, IWAE per timestep : -55.600190
====> Valid set loss: Avg. Marginal LL = -2683.8940, KL = 6.5259, Marginal LL per timestep = -44.4171, IWAE bound per timestep = -44.4305
== Best valid loss! Start Testing.. 
====> Test set loss:  Avg. Marginal LL = -2670.9885, Avg. Marginal LL per timestep = -43.5911, IWAE bound per timestep = -43.6001
Train Epoch: 3 [0/229 (0%)]	 Sequence LL: -3376.726562 KL: 33.850712 timestep LL : -43.983955,  timestep IWAE : -44.016678
Traceback (most recent call last):
  File "train.py", line 232, in <module>
    train(epoch)
  File "train.py", line 50, in train
    fivo_loss, logphat_total, _, kl, iwae_bound = model(data, mask, num_particles)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/ext2/syseo/FIVO_Gumbel/model.py", line 490, in forward
    kl = torch.distributions.kl_divergence(encoder_dist, prior_dist)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/distributions/kl.py", line 165, in kl_divergence
    return fun(p, q)
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/distributions/kl.py", line 390, in _kl_multivariatenormal_multivariatenormal
    term3 = _batch_mahalanobis(q._unbroadcasted_scale_tril, (q.loc - p.loc))
  File "/home/syseo/anaconda3/envs/jericho/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py", line 57, in _batch_mahalanobis
    M_swap = torch.triangular_solve(flat_x_swap, flat_L, upper=False)[0].pow(2).sum(-2)  # shape = b x c
KeyboardInterrupt
